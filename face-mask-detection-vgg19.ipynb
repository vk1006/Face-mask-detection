{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-10T09:07:02.063492Z","iopub.execute_input":"2022-07-10T09:07:02.063971Z","iopub.status.idle":"2022-07-10T09:07:08.129040Z","shell.execute_reply.started":"2022-07-10T09:07:02.063876Z","shell.execute_reply":"2022-07-10T09:07:08.128107Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"\n# Load data","metadata":{}},{"cell_type":"code","source":"image_size = (128,128)\n\nbase_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/'\n\n\ntrain_gen = keras.preprocessing.image.ImageDataGenerator(\n    horizontal_flip=True,\n    rescale=1./255\n)\n\nval_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_ds = train_gen.flow_from_directory(base_dir+'Train',target_size=image_size,seed=42)\nval_ds = val_gen.flow_from_directory(base_dir+'Validation',target_size=image_size,seed=42)\ntest_ds = test_gen.flow_from_directory(base_dir+'Test',target_size=image_size,seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T09:07:08.130997Z","iopub.execute_input":"2022-07-10T09:07:08.131735Z","iopub.status.idle":"2022-07-10T09:07:12.584244Z","shell.execute_reply.started":"2022-07-10T09:07:08.131679Z","shell.execute_reply":"2022-07-10T09:07:12.583623Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"* Show some images","metadata":{}},{"cell_type":"code","source":"class_names = {v:k for k,v in train_ds.class_indices.items()}\nimages,labels = next(iter(train_ds))\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(class_names[labels[i][1]])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T09:07:12.585348Z","iopub.execute_input":"2022-07-10T09:07:12.585602Z","iopub.status.idle":"2022-07-10T09:07:14.247638Z","shell.execute_reply.started":"2022-07-10T09:07:12.585576Z","shell.execute_reply":"2022-07-10T09:07:14.246783Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Build model","metadata":{}},{"cell_type":"code","source":"# we use VGG19 model for mask detection\n\nbase_model = keras.applications.VGG19(include_top=False,input_shape=image_size+(3,))\nbase_model.trainable = False\n\nmodel = keras.Sequential([\n    base_model,\n    layers.Flatten(),\n    layers.Dense(2,activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[keras.metrics.BinaryAccuracy()]\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T09:07:14.249560Z","iopub.execute_input":"2022-07-10T09:07:14.249800Z","iopub.status.idle":"2022-07-10T09:07:15.410430Z","shell.execute_reply.started":"2022-07-10T09:07:14.249774Z","shell.execute_reply":"2022-07-10T09:07:15.409618Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# View network architecture\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T09:07:15.411862Z","iopub.execute_input":"2022-07-10T09:07:15.412200Z","iopub.status.idle":"2022-07-10T09:07:15.419537Z","shell.execute_reply.started":"2022-07-10T09:07:15.412172Z","shell.execute_reply":"2022-07-10T09:07:15.418997Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Using EarlyStopping, end training when val_accuracy is not improved for 4 consecutive times\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',mode='max',\n                                patience=4,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 2 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_binary_accuracy',factor=0.5,\n                                patience=2,verbose=1)\n\n# training\nhistory = model.fit(train_ds,batch_size=32,epochs=30,\n        validation_data=val_ds,callbacks=[early_stopping,lr_scheduler])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T09:07:15.420358Z","iopub.execute_input":"2022-07-10T09:07:15.420828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Draw the learning curve","metadata":{}},{"cell_type":"code","source":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test model\nmodel.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Fine tuning  \n","metadata":{}},{"cell_type":"code","source":"# unfreeze all the layers\nbase_model.trainable = True\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=0.00001),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[keras.metrics.BinaryAccuracy()]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using EarlyStopping, end training when val_accuracy is not improved for 4 consecutive times\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',mode='max',\n                                patience=4,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 2 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_binary_accuracy',factor=0.5,\n                                patience=2,verbose=1)\n\n# training\nhistory = model.fit(train_ds,batch_size=32,epochs=30,\n        validation_data=val_ds,callbacks=[early_stopping,lr_scheduler])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test model \nmodel.evaluate(test_ds)\n\n# Our model achieved 99.89% accuracy on test data.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save model\nmodel.save('VGG19-Face Mask Detection.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"markdown","source":"## Using haar cascade to detect faces\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","metadata":{}},{"cell_type":"code","source":"# loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('../input/haarcascades/haarcascade_frontalface_default.xml')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)} # rectangle color","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now take crops of the faces detected in the image and use the model trained in the above section to determine whether the individual faces have a mask or not. Those who do not wear masks are marked in red and those who do are marked in green","metadata":{}},{"cell_type":"code","source":"def plot_image(image,subplot):\n    plt.subplot(*subplot)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.show\n\ndef predict_image(image_dir):\n    img = cv2.imread(image_dir)\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    \n    #returns a list of (x,y,w,h) tuples\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n    \n    out_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n    plt.figure(figsize=(20,20))\n    plot_image(out_img,(1,2,1))\n    \n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = out_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])/255.0\n        mask_result = model.predict(crop).argmax()\n        cv2.rectangle(out_img,(x,y),(x+w,y+h),dist_label[mask_result],1)\n    \n    plot_image(out_img,(1,2,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_image('../input/face-mask-detection/images/maksssksksss244.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_image('../input/face-mask-detection/images/maksssksksss174.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_image('../input/face-mask-detection/images/maksssksksss388.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}